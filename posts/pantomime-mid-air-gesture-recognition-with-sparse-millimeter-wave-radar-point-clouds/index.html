<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds" /><meta name="author" content="Dariush Salami" /><meta property="og:locale" content="en" /><meta name="description" content="Demo video of Pantomime Before we dive into the technical explanations, let’s watch the demo video of Pantomime. In this demo, we have implemented an interface to control the PowerPoint presentation using Pantomime." /><meta property="og:description" content="Demo video of Pantomime Before we dive into the technical explanations, let’s watch the demo video of Pantomime. In this demo, we have implemented an interface to control the PowerPoint presentation using Pantomime." /><link rel="canonical" href="https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/" /><meta property="og:url" content="https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/" /><meta property="og:site_name" content="Dariush Salami" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-06T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds" /><meta name="twitter:site" content="@dariush_salami" /><meta name="twitter:creator" content="@Dariush Salami" /><meta name="google-site-verification" content="0c713MKXMtoMoozIKWkuwmOvaqbWFlhKZBTSuprgU8g" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Dariush Salami"},"headline":"Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds","dateModified":"2022-05-06T14:34:47+03:00","datePublished":"2021-11-06T00:00:00+02:00","description":"Demo video of Pantomime Before we dive into the technical explanations, let’s watch the demo video of Pantomime. In this demo, we have implemented an interface to control the PowerPoint presentation using Pantomime.","url":"https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/"},"@context":"https://schema.org"}</script><title>Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds | Dariush Salami</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Dariush Salami"><meta name="application-name" content="Dariush Salami"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Dariush Salami</a></div><div class="site-subtitle font-italic">A machine learning researcher interested in fitness :)</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/bibliography/" class="nav-link"> <i class="fa-fw fas fa-graduation-cap ml-xl-3 mr-xl-3 unloaded"></i> <span>BIBLIOGRAPHY</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dariush-salami" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/dariush_salami" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['dariush.salami','aalto.fi'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Dariush Salami </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, Nov 6, 2021, 12:00 AM +0200" >Nov 6, 2021<i class="unloaded">2021-11-06T00:00:00+02:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, May 6, 2022, 2:34 PM +0300" >May 6<i class="unloaded">2022-05-06T14:34:47+03:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="831 words">4 min read</span></div></div><div class="post-content"><h2 id="demo-video-of-pantomime">Demo video of Pantomime</h2><p>Before we dive into the technical explanations, let’s watch the demo video of Pantomime. In this demo, we have implemented an interface to control the PowerPoint presentation using Pantomime.</p><div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/1_3q1mMtcFs" allowfullscreen=""></iframe></div><h2 id="presentation-of-the-paper-in-ubicomp-2021">Presentation of the paper in UBICOMP 2021</h2><p>Now it is time to understand the technical details of the Pantomime system. Here is the video presented in UBICOMP 2021:</p><div class="embed-responsive embed-responsive-16by9"> <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/V2DI2Q51yIQ" allowfullscreen=""></iframe></div><h2 id="how-to-run-pantomime-model">How to run Pantomime model?</h2><p>To be able to run Pantomime on your own dataset or to reproduce the results there are three steps that should be done.</p><h3 id="dataset">Dataset</h3><p>First, you need to download the dataset that we have made publicly available. It is published on Zenodo:</p><pre>https://zenodo.org/record/4459969#.YnT9n3VBw5k</pre><p>Having downloaded the dataset, you will have a tree-like folder structure:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>+-- {dataset_date}
|   +-- primary_exp
|       +-- {enviornment}
|           +-- {distance}
|               +-- {angle}
|                   +-- {speed}
|                       +-- {user}
|                           +-- {gesture}
|                               +-- {trial}.pkl
|   +-- supp_exp
|       +-- {enviornment}
|           +-- {distance}
|               +-- {angle}
|                   +-- {speed}
|                       +-- {user}
|                           +-- {gesture}
|                               +-- {trial}.pkl
</pre></table></code></div></div><p>where <code class="language-plaintext highlighter-rouge">{dataset_date}, {enviornment}, {distance}, {angle}, {speed}, {user}, {gesture},</code> and <code class="language-plaintext highlighter-rouge">{trial}</code> are the date of the dataset release, the enviornments in which the dataset is collected (open, office, industrial, multi_people, occluded, and restaurant), the distance from the participant to the radar (1m, 2m, 3m, 4m, and 5m), the angle w.r.t. radar (-45, -30, -15, 0, 15, 30, and 45), the speed of the gesture performance (slow, normal, and fast), the anonymous ID of the participant, the gesture class, and the trial, respectively.</p><p>As you may have noticed, the format used for the data is <code class="language-plaintext highlighter-rouge">pickle</code>. <a href="https://pypi.org/project/pickle5/" target="_blank">Pickle</a> is a library used for serializing data into files in Python. After deserializing the pickle file, you will have a <a href="https://numpy.org/" target="_blank">Numpy</a> array. The array has the following shape:</p><pre>{frames}x{points}x{3 or 4}</pre><p>The first dimension is the frames in the gesture trial. Note that the number of frames is not fixed. It varies from trial to trial. The second dimension is the points in frame. Again, keep in mind that each frame can have a different number of points. Finally, the last dimension is <code class="language-plaintext highlighter-rouge">x, y, z</code>, and <code class="language-plaintext highlighter-rouge">intensity</code>. The intensity can be missing for some gestures. Now, you have the dataset and you know how to process the files :) Let’s go to the next step.</p><h3 id="preprocessing-pipeline">Preprocessing Pipeline</h3><p>In the second step, we probably need to perform preprocessing on the dataset. Again, you need to clone the repository for preprocessing script:</p><pre>https://version.aalto.fi/gitlab/salamid1/rf-point-cloud-gesture-recognition</pre><p>The preprocessing pipeline is written using a workflow management system called <a href="https://snakemake.readthedocs.io/en/stable/" target="_blank">Snakemake</a>. Make sure you are familiar with Snakemake. There are three main files in the preprocessing pipeline:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>+-- Snakefile - the entry file for the pipeline where the steps are defined
+-- primary_exp_config.json - the configuration file for the primary experiments
+-- supp_exp_config.json - the configuration file for the supplementary experiments
</pre></table></code></div></div><p>You can use the pre-defined steps that we have developed for the model. Needless to say, you can come up with your own preprocessing steps in this part to make a more efficient model! This preprocessing pipeline is used in all my papers from <code class="language-plaintext highlighter-rouge">Pantomime</code> to <code class="language-plaintext highlighter-rouge">Tesla</code>.</p><h3 id="training-pantomime-model">Training Pantomime Model</h3><p>Now, you hopefully have your data preprocessed using the pipeline and looking forward to training Pantomime on your data! As we have mentioned in the paper, the model is pretty huge. So, at first, make sure you have a strong enough GPU to train the model. Then, you need to download the source code of the model from the link below:</p><pre>https://zenodo.org/record/4459969#.YnT9n3VBw5k</pre><p>The next step is to compile the custom tf operators that we have used in the model. Here is the link in <code class="language-plaintext highlighter-rouge">PointNet++</code> repository that you can use to learn how to compile the tf operators:</p><pre>https://github.com/charlesq34/pointnet2</pre><p>After compiling the operators, you can run <code class="language-plaintext highlighter-rouge">train.py</code> with different parameters to train your model. But before we finish this post, there are a few things that you need to pay attention to:</p><ul><li>The training scripts read the dataset file in a different format namely <a href="https://www.h5py.org/" target="_blank">H5PY</a>. But fortunately, we already have that final step of converting pickle file to h5py file in the preprocessing pipeline.<li>The training script read a txt file pointing out to the h5py file mentioned in the previous step. As a result, you need to create a text file and then simply put the path to the h5py file in it to be able to run the model.<li>Since Pantomime applies PointNet++ on each frame of the dataset, using many frames will increase the computational load significantly. If your processing power is low, it is highly recommended to use less number of frames per gesture. Or, you can check out my recent paper entitled <code class="language-plaintext highlighter-rouge">Tesla</code> which is way more computationally efficient than Pantomime.</ul><p>In the end, if you have any further questions or feedback, you can reflect them in the comments section below or drop me emails directly :)</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/phd/'>PhD</a>, <a href='/categories/research/'>Research</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/gesture/" class="post-tag no-text-decoration" >gesture</a> <a href="/tags/rf-sensing/" class="post-tag no-text-decoration" >rf-sensing</a> <a href="/tags/human-computer-interaction/" class="post-tag no-text-decoration" >human-computer-interaction</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ml</a> <a href="/tags/ai/" class="post-tag no-text-decoration" >ai</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine-learning</a> <a href="/tags/mmwave/" class="post-tag no-text-decoration" >mmwave</a> <a href="/tags/radar/" class="post-tag no-text-decoration" >radar</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds - Dariush Salami&url=https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds - Dariush Salami&u=https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds - Dariush Salami&url=https://dariush-salami.github.io/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/pantomime-mid-air-gesture-recognition-with-sparse-millimeter-wave-radar-point-clouds/">Pantomime: Mid-Air Gesture Recognition with Sparse Millimeter-Wave Radar Point Clouds</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">ai</a> <a class="post-tag" href="/tags/gesture/">gesture</a> <a class="post-tag" href="/tags/human-computer-interaction/">human-computer-interaction</a> <a class="post-tag" href="/tags/machine-learning/">machine-learning</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mmwave/">mmwave</a> <a class="post-tag" href="/tags/radar/">radar</a> <a class="post-tag" href="/tags/rf-sensing/">rf-sensing</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div class="post-navigation d-flex justify-content-between"> <span class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></span> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div><div class="pt-2 pb-2"><div class="giscus"></div></div><script src="https://giscus.app/client.js" data-repo="dariush-salami/dariush-salami.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnkzNTMxMTE3OTk=" data-category="Announcements" data-category-id="DIC_kwDOFQwO984B_wt6" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-theme="dark_dimmed" data-lang="en" crossorigin="anonymous" async> </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/dariush_salami">Dariush Salami</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ai/">ai</a> <a class="post-tag" href="/tags/gesture/">gesture</a> <a class="post-tag" href="/tags/human-computer-interaction/">human computer interaction</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mmwave/">mmwave</a> <a class="post-tag" href="/tags/radar/">radar</a> <a class="post-tag" href="/tags/rf-sensing/">rf sensing</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-MPLHXFWN8E"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-MPLHXFWN8E'); }); </script>
